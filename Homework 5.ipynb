{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1d3e9c",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "## Professor Nathan Kutz\n",
    "## EE399\n",
    "## By: Gerin George\n",
    "\n",
    "Link to private GitHub Repo:\n",
    "\n",
    "https://github.com/gering92/EE399-Work\n",
    "\n",
    "Click on Homework 5 Writeup to see the writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7d067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy import integrate\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd5a2ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Generating Lorenz data for rho = 10\n",
      "Lorenz data generated for rho = 10\n",
      "Generating Lorenz data for rho = 28\n",
      "Lorenz data generated for rho = 28\n",
      "Generating Lorenz data for rho = 40\n",
      "Lorenz data generated for rho = 40\n",
      "Training data generated.\n",
      "Training model...\n",
      "Epoch 10, loss = 209.141693\n",
      "Epoch 20, loss = 115.481621\n",
      "Epoch 30, loss = 48.743965\n",
      "Epoch 40, loss = 16.141109\n",
      "Epoch 50, loss = 6.935210\n",
      "Epoch 60, loss = 3.275884\n",
      "Epoch 70, loss = 2.436378\n",
      "Epoch 80, loss = 2.008651\n",
      "Epoch 90, loss = 1.496558\n",
      "Epoch 100, loss = 1.156174\n",
      "Model training complete.\n",
      "Testing model...\n",
      "Generating Lorenz data for rho = 17\n",
      "Lorenz data generated for rho = 17\n",
      "Test MSE loss for rho = 17: 78.122292\n",
      "Generating Lorenz data for rho = 35\n",
      "Lorenz data generated for rho = 35\n",
      "Test MSE loss for rho = 35: 263.452789\n",
      "Model testing complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the model\n",
    "class FFNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_and_test_model(rho_train_values, rho_test_values):\n",
    "    print(\"Generating training data...\")\n",
    "    # Generate training data\n",
    "    nn_input = []\n",
    "    nn_output = []\n",
    "    for rho in rho_train_values:\n",
    "        temp_input, temp_output = generate_lorenz_data(rho)\n",
    "        nn_input.append(temp_input)\n",
    "        nn_output.append(temp_output)\n",
    "    nn_input = np.vstack(nn_input)\n",
    "    nn_output = np.vstack(nn_output)\n",
    "    print(\"Training data generated.\")\n",
    "    \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_input = torch.from_numpy(nn_input).float()\n",
    "    nn_output = torch.from_numpy(nn_output).float()\n",
    "\n",
    "    # Create model instance\n",
    "    model = FFNNModel()\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0008)\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    # Train the model\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(nn_input)\n",
    "        loss = criterion(outputs, nn_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, loss = {loss.item():.6f}\")\n",
    "    print(\"Model training complete.\")\n",
    "    \n",
    "    print(\"Testing model...\")\n",
    "    # Test the model\n",
    "    for rho in rho_test_values:\n",
    "        test_input, test_output = generate_lorenz_data(rho)\n",
    "        test_input = torch.from_numpy(test_input).float()\n",
    "        test_output = torch.from_numpy(test_output).float()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            future_state_predictions = []\n",
    "            current_state = test_input[0:1]\n",
    "            for _ in range(len(test_input) - 1):\n",
    "                next_state_prediction = model(current_state)\n",
    "                future_state_predictions.append(next_state_prediction)\n",
    "                current_state = next_state_prediction\n",
    "\n",
    "            future_state_predictions = torch.vstack(future_state_predictions)\n",
    "        mse_loss = criterion(future_state_predictions, test_output[:-1]).item()\n",
    "        print(f\"Test MSE loss for rho = {rho}: {mse_loss:.6f}\")\n",
    "    print(\"Model testing complete.\")\n",
    "\n",
    "def generate_lorenz_data(rho):\n",
    "    print(f\"Generating Lorenz data for rho = {rho}\")\n",
    "    dt = 0.01\n",
    "    T = 8\n",
    "    t = np.arange(0, T + dt, dt)\n",
    "    beta = 8 / 3\n",
    "    sigma = 10\n",
    "\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t) for x0_j in x0])\n",
    "\n",
    "    nn_input = np.zeros((100 * (len(t) - 1), 3))\n",
    "    nn_output = np.zeros_like(nn_input)\n",
    "\n",
    "    for j in range(100):\n",
    "        nn_input[j * (len(t) - 1):(j + 1) * (len(t) - 1), :] = x_t[j, :-1, :]\n",
    "        nn_output[j * (len(t) - 1):(j + 1) * (len(t) - 1), :] = x_t[j, 1:, :]\n",
    "\n",
    "    print(f\"Lorenz data generated for rho = {rho}\")\n",
    "    return nn_input, nn_output\n",
    "\n",
    "# Train and test the model for different rho values\n",
    "rho_train_values = [10, 28, 40]\n",
    "rho_test_values = [17, 35]\n",
    "train_and_test_model(rho_train_values, rho_test_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236a19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(rho_values):\n",
    "    sigma = 10\n",
    "    beta = 8/3\n",
    "    dt = 0.02\n",
    "    T = 4\n",
    "    t = np.arange(0, T+dt, dt)\n",
    "\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho_current=None):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho_current - z) - y, x * y - beta * z]\n",
    "\n",
    "    nn_input = []\n",
    "    nn_output = []\n",
    "\n",
    "    for rho in rho_values:\n",
    "        x0 = -15 + 30 * np.random.random((50, 3))\n",
    "        x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t, args=(sigma, beta, rho)) for x0_j in x0])\n",
    "\n",
    "        for j in range(50):\n",
    "            nn_input.extend(x_t[j,:-1,:])\n",
    "            nn_output.extend(x_t[j,1:,:])\n",
    "\n",
    "    return np.array(nn_input), np.array(nn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b460bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Training data generation completed.\n",
      "\n",
      "Defining the LSTM model...\n",
      "Model defined.\n",
      "\n",
      "Initializing the model...\n",
      "Model initialized.\n",
      "\n",
      "Defining loss criterion and optimizer...\n",
      "Loss criterion and optimizer defined.\n",
      "\n",
      "Training the model...\n",
      "Epoch:  0\n",
      "Current loss:  307.0986328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geringeorge/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([30000, 3])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10\n",
      "Current loss:  238.1931610107422\n",
      "Epoch:  20\n",
      "Current loss:  194.8776397705078\n",
      "Epoch:  30\n",
      "Current loss:  163.07229614257812\n",
      "Epoch:  40\n",
      "Current loss:  142.15342712402344\n",
      "Epoch:  50\n",
      "Current loss:  129.97702026367188\n",
      "Epoch:  60\n",
      "Current loss:  124.38225555419922\n",
      "Epoch:  70\n",
      "Current loss:  122.33444213867188\n",
      "Epoch:  80\n",
      "Current loss:  121.86066436767578\n",
      "Epoch:  90\n",
      "Current loss:  121.84431457519531\n",
      "Training completed.\n",
      "\n",
      "\n",
      "Generating test data for rho = 17...\n",
      "Test data generation for rho = 17 completed.\n",
      "\n",
      "Running prediction on test data for rho = 17...\n",
      "Prediction for rho = 17 completed.\n",
      "\n",
      "Calculating MSE loss on test data for rho = 17...\n",
      "Test MSE Loss for rho = 17:  66.92090606689453\n",
      "\n",
      "Generating test data for rho = 35...\n",
      "Test data generation for rho = 35 completed.\n",
      "\n",
      "Running prediction on test data for rho = 35...\n",
      "Prediction for rho = 35 completed.\n",
      "\n",
      "Calculating MSE loss on test data for rho = 35...\n",
      "Test MSE Loss for rho = 35:  135.4553985595703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geringeorge/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10000, 3])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# LSTM test\n",
    "\n",
    "print(\"Generating training data...\")\n",
    "train_rho_values = [10, 28, 40]\n",
    "x_train, y_train = generate_data(train_rho_values)\n",
    "x_train_torch = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.float32)\n",
    "print(\"Training data generation completed.\\n\")\n",
    "\n",
    "print(\"Defining the LSTM model...\")\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, 1, self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, 1, self.hidden_dim).requires_grad_()\n",
    "        x = x.unsqueeze(0)  # Add an extra dimension for batching\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "print(\"Model defined.\\n\")\n",
    "\n",
    "print(\"Initializing the model...\")\n",
    "model = LSTMModel(3, 50, 3, 1)\n",
    "print(\"Model initialized.\\n\")\n",
    "\n",
    "print(\"Defining loss criterion and optimizer...\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "print(\"Loss criterion and optimizer defined.\\n\")\n",
    "\n",
    "print(\"Training the model...\")\n",
    "for epoch in range(100):\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: \", epoch)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x_train_torch)\n",
    "    loss = criterion(outputs, y_train_torch)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Current loss: \", loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"Training completed.\\n\")\n",
    "\n",
    "test_rho_values = [17, 35]\n",
    "\n",
    "for rho in test_rho_values:\n",
    "    print(f\"\\nGenerating test data for rho = {rho}...\")\n",
    "    x_test, y_test = generate_data([rho])  # Generate test data for this rho\n",
    "    x_test_torch = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test_torch = torch.tensor(y_test, dtype=torch.float32)\n",
    "    print(f\"Test data generation for rho = {rho} completed.\\n\")\n",
    "\n",
    "    print(f\"Running prediction on test data for rho = {rho}...\")\n",
    "    y_pred = model(x_test_torch)\n",
    "    print(f\"Prediction for rho = {rho} completed.\\n\")\n",
    "\n",
    "    print(f\"Calculating MSE loss on test data for rho = {rho}...\")\n",
    "    mse_loss = criterion(y_pred, y_test_torch)\n",
    "    print(f\"Test MSE Loss for rho = {rho}: \", mse_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680468ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Training data generation completed.\n",
      "\n",
      "Defining the ESN model...\n",
      "Model defined.\n",
      "\n",
      "Initializing the model...\n",
      "Model initialized.\n",
      "\n",
      "Defining loss criterion and optimizer...\n",
      "Loss criterion and optimizer defined.\n",
      "\n",
      "Training the model...\n",
      "Epoch:  0\n",
      "Current loss:  304.5351867675781\n",
      "Epoch:  10\n",
      "Current loss:  237.17877197265625\n",
      "Epoch:  20\n",
      "Current loss:  183.053466796875\n",
      "Epoch:  30\n",
      "Current loss:  142.16448974609375\n",
      "Epoch:  40\n",
      "Current loss:  113.07328796386719\n",
      "Epoch:  50\n",
      "Current loss:  93.4913101196289\n",
      "Epoch:  60\n",
      "Current loss:  80.96036529541016\n",
      "Epoch:  70\n",
      "Current loss:  73.31140899658203\n",
      "Epoch:  80\n",
      "Current loss:  68.84037017822266\n",
      "Epoch:  90\n",
      "Current loss:  66.31124877929688\n",
      "Training completed.\n",
      "\n",
      "\n",
      "Generating test data for rho = 17...\n",
      "Test data generation for rho = 17 completed.\n",
      "\n",
      "Resetting model state and running prediction on test data for rho = 17...\n",
      "Prediction for rho = 17 completed.\n",
      "\n",
      "Calculating MSE loss on test data for rho = 17...\n",
      "Test MSE Loss for rho = 17:  28.195171356201172\n",
      "\n",
      "Generating test data for rho = 35...\n",
      "Test data generation for rho = 35 completed.\n",
      "\n",
      "Resetting model state and running prediction on test data for rho = 35...\n",
      "Prediction for rho = 35 completed.\n",
      "\n",
      "Calculating MSE loss on test data for rho = 35...\n",
      "Test MSE Loss for rho = 35:  67.7677001953125\n"
     ]
    }
   ],
   "source": [
    "# Echo State Network (ESN) test\n",
    "print(\"Generating training data...\")\n",
    "train_rho_values = [10, 28, 40]\n",
    "x_train, y_train = generate_data(train_rho_values)\n",
    "x_train_torch = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.float32)\n",
    "print(\"Training data generation completed.\\n\")\n",
    "\n",
    "print(\"Defining the ESN model...\")\n",
    "class ESN(nn.Module):\n",
    "    def __init__(self, input_dim, reservoir_dim, output_dim):\n",
    "        super(ESN, self).__init__()\n",
    "        self.reservoir_dim = reservoir_dim\n",
    "        self.input_weights = nn.Parameter(torch.randn(input_dim, reservoir_dim) / np.sqrt(input_dim), requires_grad=False)\n",
    "        self.reservoir_weights = nn.Parameter(torch.randn(reservoir_dim, reservoir_dim), requires_grad=False)\n",
    "        self.output_weights = nn.Parameter(torch.zeros(reservoir_dim, output_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        reservoir_state = torch.tanh(x @ self.input_weights + self.reservoir_state @ self.reservoir_weights)\n",
    "        self.reservoir_state = reservoir_state\n",
    "        return reservoir_state @ self.output_weights\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.reservoir_state = torch.zeros(1, self.reservoir_dim)\n",
    "\n",
    "print(\"Model defined.\\n\")\n",
    "\n",
    "print(\"Initializing the model...\")\n",
    "model = ESN(3, 50, 3)\n",
    "model.reset_state()\n",
    "print(\"Model initialized.\\n\")\n",
    "\n",
    "print(\"Defining loss criterion and optimizer...\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "print(\"Loss criterion and optimizer defined.\\n\")\n",
    "\n",
    "print(\"Training the model...\")\n",
    "for epoch in range(100):\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: \", epoch)\n",
    "    optimizer.zero_grad()\n",
    "    model.reset_state()\n",
    "    outputs = model(x_train_torch)\n",
    "    loss = criterion(outputs, y_train_torch)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Current loss: \", loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"Training completed.\\n\")\n",
    "\n",
    "test_rho_values = [17, 35]\n",
    "\n",
    "for rho in test_rho_values:\n",
    "    print(f\"\\nGenerating test data for rho = {rho}...\")\n",
    "    x_test, y_test = generate_data([rho])  # Generate test data for this rho\n",
    "    x_test_torch = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test_torch = torch.tensor(y_test, dtype=torch.float32)\n",
    "    print(f\"Test data generation for rho = {rho} completed.\\n\")\n",
    "\n",
    "    print(f\"Resetting model state and running prediction on test data for rho = {rho}...\")\n",
    "    model.reset_state()\n",
    "    y_pred = model(x_test_torch)\n",
    "    print(f\"Prediction for rho = {rho} completed.\\n\")\n",
    "\n",
    "    print(f\"Calculating MSE loss on test data for rho = {rho}...\")\n",
    "    mse_loss = criterion(y_pred, y_test_torch)\n",
    "    print(f\"Test MSE Loss for rho = {rho}: \", mse_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52976e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Training data generation completed.\n",
      "\n",
      "Defining the RNN model...\n",
      "Model defined.\n",
      "\n",
      "Initializing the model...\n",
      "Model initialized.\n",
      "\n",
      "Defining loss criterion and optimizer...\n",
      "Loss criterion and optimizer defined.\n",
      "\n",
      "Training the model...\n",
      "Epoch:  0\n",
      "Current loss:  317.39154052734375\n",
      "Epoch:  10\n",
      "Current loss:  231.94017028808594\n",
      "Epoch:  20\n",
      "Current loss:  186.25241088867188\n",
      "Epoch:  30\n",
      "Current loss:  153.58364868164062\n",
      "Epoch:  40\n",
      "Current loss:  134.9705352783203\n",
      "Epoch:  50\n",
      "Current loss:  126.64192199707031\n",
      "Epoch:  60\n",
      "Current loss:  123.91343688964844\n",
      "Epoch:  70\n",
      "Current loss:  123.38780212402344\n",
      "Epoch:  80\n",
      "Current loss:  123.3909912109375\n",
      "Epoch:  90\n",
      "Current loss:  123.40885925292969\n",
      "Training completed.\n",
      "\n",
      "\n",
      "Generating test data for rho = 17...\n",
      "Test data generation for rho = 17 completed.\n",
      "\n",
      "Running prediction on test data for rho = 17...\n",
      "Prediction for rho = 17 completed.\n",
      "\n",
      "Calculating MSE loss on test data for rho = 17...\n",
      "Test MSE Loss for rho = 17:  65.30891418457031\n",
      "\n",
      "Generating test data for rho = 35...\n",
      "Test data generation for rho = 35 completed.\n",
      "\n",
      "Running prediction on test data for rho = 35...\n",
      "Prediction for rho = 35 completed.\n",
      "\n",
      "Calculating MSE loss on test data for rho = 35...\n",
      "Test MSE Loss for rho = 35:  130.9735107421875\n"
     ]
    }
   ],
   "source": [
    "# RNN Test\n",
    "\n",
    "\n",
    "print(\"Generating training data...\")\n",
    "train_rho_values = [10, 28, 40]\n",
    "x_train, y_train = generate_data(train_rho_values)\n",
    "x_train_torch = torch.tensor(x_train, dtype=torch.float32).unsqueeze(0)\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.float32)\n",
    "print(\"Training data generation completed.\\n\")\n",
    "\n",
    "print(\"Defining the RNN model...\")\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "print(\"Model defined.\\n\")\n",
    "\n",
    "print(\"Initializing the model...\")\n",
    "model = SimpleRNN(3, 50, 3)\n",
    "print(\"Model initialized.\\n\")\n",
    "\n",
    "print(\"Defining loss criterion and optimizer...\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "print(\"Loss criterion and optimizer defined.\\n\")\n",
    "\n",
    "print(\"Training the model...\")\n",
    "for epoch in range(100):\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: \", epoch)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x_train_torch)\n",
    "    loss = criterion(outputs, y_train_torch)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Current loss: \", loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"Training completed.\\n\")\n",
    "\n",
    "test_rho_values = [17, 35]\n",
    "\n",
    "for rho in test_rho_values:\n",
    "    print(f\"\\nGenerating test data for rho = {rho}...\")\n",
    "    x_test, y_test = generate_data([rho])  # Generate test data for this rho\n",
    "    x_test_torch = torch.tensor(x_test, dtype=torch.float32).unsqueeze(0)\n",
    "    y_test_torch = torch.tensor(y_test, dtype=torch.float32)\n",
    "    print(f\"Test data generation for rho = {rho} completed.\\n\")\n",
    "\n",
    "    print(f\"Running prediction on test data for rho = {rho}...\")\n",
    "    y_pred = model(x_test_torch)\n",
    "    print(f\"Prediction for rho = {rho} completed.\\n\")\n",
    "\n",
    "    print(f\"Calculating MSE loss on test data for rho = {rho}...\")\n",
    "    mse_loss = criterion(y_pred, y_test_torch)\n",
    "    print(f\"Test MSE Loss for rho = {rho}: \", mse_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f8310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057e34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd043a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
